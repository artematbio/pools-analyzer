#!/usr/bin/env python3
"""
Bio Daily Analyzer v2.0 - LP Management & Market Making Intelligence
–ï–∂–µ–¥–Ω–µ–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ LP –ø–æ–∑–∏—Ü–∏–π –∏ –ø–æ–≤—ã—à–µ–Ω–∏—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ —Ç–æ–∫–µ–Ω–æ–≤
"""

import os
import asyncio
import httpx
import json
from datetime import datetime, timedelta
from decimal import Decimal
from typing import Dict, List, Optional, Any
from database_handler import supabase_handler
from telegram_sender import TelegramSender
import time

# API –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
GROK_API_KEY = os.getenv('GROK_API_KEY')

# API URLs
OPENAI_API_URL = "https://api.openai.com/v1/chat/completions"
GROK_API_URL = "https://api.x.ai/v1/chat/completions"

class BioLPAnalyzer:
    def __init__(self):
        self.supabase = supabase_handler
        self.analysis_time = datetime.utcnow()
        self.market_context = {}
        
    async def translate_to_russian(self, english_text: str) -> str:
        """–ü–µ—Ä–µ–≤–æ–¥–∏—Ç –∞–Ω–≥–ª–∏–π—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫"""
        
        if not english_text or not GROK_API_KEY:
            return english_text
            
        translation_prompt = f"""–ü–µ—Ä–µ–≤–µ–¥–∏ —Å–ª–µ–¥—É—é—â–∏–π –∞–Ω–∞–ª–∏–∑ Bio Protocol LP Intelligence –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫. 
–°–æ—Ö—Ä–∞–Ω–∏ –≤—Å—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É, —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ, —á–∏—Å–ª–∞ –∏ –∫–ª—é—á–µ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã.
–ü–µ—Ä–µ–≤–æ–¥–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –¥–ª—è DeFi –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.

–¢–µ–∫—Å—Ç –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞:
{english_text}"""
        
        headers = {
            "Authorization": f"Bearer {GROK_API_KEY}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": "grok-4-0709",
            "messages": [
                {"role": "system", "content": "–¢—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫ DeFi –∏ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤. –ü–µ—Ä–µ–≤–æ–¥–∏ —Ç–æ—á–Ω–æ, —Å–æ—Ö—Ä–∞–Ω—è—è –≤—Å—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã."},
                {"role": "user", "content": translation_prompt}
            ],
            "max_tokens": 4000,
            "temperature": 0.1
        }
        
        try:
            print("üåê –ü–µ—Ä–µ–≤–æ–¥–∏–º –∞–Ω–∞–ª–∏–∑ –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫...")
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    GROK_API_URL,
                    headers=headers,
                    json=payload,
                    timeout=120
                )
                
                if response.status_code == 200:
                    data = response.json()
                    if "choices" in data and len(data["choices"]) > 0:
                        translation = data["choices"][0]["message"]["content"]
                        print(f"‚úÖ –ü–µ—Ä–µ–≤–æ–¥ –≤—ã–ø–æ–ª–Ω–µ–Ω ({len(translation)} —Å–∏–º–≤–æ–ª–æ–≤)")
                        return translation
                    
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞: {response.status_code} - {response.text}")
                return english_text
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ API –ø–µ—Ä–µ–≤–æ–¥–∞: {e}")
            return english_text
        
    async def get_market_context(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Ä—ã–Ω–æ—á–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç SOL/ETH –¥–ª—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏—Ö —Ä–µ—à–µ–Ω–∏–π"""
        
        market_data = {
            "sol_price": None,
            "eth_price": None,
            "sol_24h_change": None,
            "eth_24h_change": None,
            "btc_dominance": None,
            "total_market_cap": None
        }
        
        try:
            print("üåç –ü–æ–ª—É—á–∞—é —Ä—ã–Ω–æ—á–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç SOL/ETH...")
            
            # CoinGecko API –¥–ª—è –±–∞–∑–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            coingecko_url = "https://api.coingecko.com/api/v3/simple/price"
            params = {
                "ids": "solana,ethereum,bitcoin",
                "vs_currencies": "usd",
                "include_24hr_change": "true",
                "include_market_cap": "true"
            }
            
            async with httpx.AsyncClient() as client:
                response = await client.get(coingecko_url, params=params, timeout=10)
                
                if response.status_code == 200:
                    data = response.json()
                    
                    # SOL –¥–∞–Ω–Ω—ã–µ
                    if "solana" in data:
                        market_data["sol_price"] = data["solana"].get("usd")
                        market_data["sol_24h_change"] = data["solana"].get("usd_24h_change")
                    
                    # ETH –¥–∞–Ω–Ω—ã–µ 
                    if "ethereum" in data:
                        market_data["eth_price"] = data["ethereum"].get("usd")
                        market_data["eth_24h_change"] = data["ethereum"].get("usd_24h_change")
                    
                    # BTC –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                    if "bitcoin" in data:
                        market_data["btc_price"] = data["bitcoin"].get("usd")
                        market_data["btc_24h_change"] = data["bitcoin"].get("usd_24h_change")
                    
                    print(f"     ‚úÖ SOL: ${market_data['sol_price']:.2f} ({market_data['sol_24h_change']:+.2f}%)")
                    print(f"     ‚úÖ ETH: ${market_data['eth_price']:.2f} ({market_data['eth_24h_change']:+.2f}%)")
                else:
                    print(f"     ‚ö†Ô∏è CoinGecko API –æ—à–∏–±–∫–∞: {response.status_code}")
                    
        except Exception as e:
            print(f"     ‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")
        
        return market_data
    
    async def validate_tokens_externally(self, tokens_data: List[Dict]) -> Dict[str, Any]:
        """–°–≤–µ—Ä—è–µ—Ç –¥–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–æ–≤ —Å DexScreener –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–π"""
        
        validation_results = {
            "discrepancies": [],
            "missing_listings": [],
            "price_differences": [],
            "validation_summary": {}
        }
        
        try:
            print("üîç –ü—Ä–æ–≤–µ—Ä—è—é —Ç–æ–∫–µ–Ω—ã –Ω–∞ DexScreener...")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–æ–ø-5 —Ç–æ–∫–µ–Ω–æ–≤ –ø–æ FDV —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å API
            top_tokens = sorted(tokens_data, key=lambda x: float(x.get('FDV', 0) or 0), reverse=True)[:5]
            
            for token in top_tokens:
                symbol = token.get('Token', '')
                our_price = token.get('Price', 0)
                our_fdv = float(token.get('FDV', 0) or 0)
                
                if not symbol or symbol == 'BIO':  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º BIO –∏ –ø—É—Å—Ç—ã–µ
                    continue
                
                try:
                    # DexScreener API –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ç–æ–∫–µ–Ω–∞
                    search_url = f"https://api.dexscreener.com/latest/dex/search?q={symbol}"
                    
                    async with httpx.AsyncClient() as client:
                        response = await client.get(search_url, timeout=10)
                        
                        if response.status_code == 200:
                            data = response.json()
                            pairs = data.get('pairs', [])
                            
                            if pairs:
                                # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—É—é –ø–∞—Ä—É –∫–∞–∫ —Å—Å—ã–ª–∫—É
                                pair = pairs[0]
                                dex_price = float(pair.get('priceUsd', 0) or 0)
                                dex_fdv = float(pair.get('fdv', 0) or 0)
                                
                                # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ü–µ–Ω—ã (—Ä–∞–∑–Ω–∏—Ü–∞ > 5%)
                                if our_price and dex_price:
                                    price_diff = abs(our_price - dex_price) / our_price * 100
                                    if price_diff > 5:
                                        validation_results["price_differences"].append({
                                            "token": symbol,
                                            "our_price": our_price,
                                            "dex_price": dex_price,
                                            "difference_pct": price_diff
                                        })
                                
                                print(f"     ‚úÖ {symbol}: DexScreener –Ω–∞–π–¥–µ–Ω, —Ü–µ–Ω–∞ ${dex_price:.6f}")
                            else:
                                validation_results["missing_listings"].append({
                                    "token": symbol,
                                    "reason": "Not found on DexScreener"
                                })
                                print(f"     ‚ö†Ô∏è {symbol}: –ù–µ –Ω–∞–π–¥–µ–Ω –Ω–∞ DexScreener")
                        else:
                            print(f"     ‚ùå {symbol}: DexScreener API –æ—à–∏–±–∫–∞ {response.status_code}")
                            
                    # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                    await asyncio.sleep(1)
                    
                except Exception as e:
                    print(f"     ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ {symbol}: {e}")
                    
        except Exception as e:
            print(f"     ‚ùå –û–±—â–∞—è –æ—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
        
        # –°—É–º–º–∞—Ä–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        validation_results["validation_summary"] = {
            "tokens_checked": len(top_tokens),
            "missing_count": len(validation_results["missing_listings"]),
            "price_discrepancies": len(validation_results["price_differences"]),
            "health_score": max(0, 100 - (len(validation_results["missing_listings"]) * 20) - (len(validation_results["price_differences"]) * 10))
        }
        
        print(f"     üìä –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ {len(top_tokens)} —Ç–æ–∫–µ–Ω–æ–≤, –∑–¥–æ—Ä–æ–≤—å–µ —ç–∫–æ—Å–∏—Å—Ç–µ–º—ã: {validation_results['validation_summary']['health_score']}/100")
        
        return validation_results
        
    async def collect_comprehensive_data(self) -> Dict[str, Any]:
        """–°–æ–±–∏—Ä–∞–µ—Ç –ø–æ–ª–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è LP –∞–Ω–∞–ª–∏–∑–∞"""
        
        print("üìä –°–æ–±–∏—Ä–∞—é –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è LP –∞–Ω–∞–ª–∏–∑–∞...")
        print(f"‚è∞ –í—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞: {self.analysis_time.strftime('%Y-%m-%d %H:%M UTC')}")
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä—ã–Ω–æ—á–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        self.market_context = await self.get_market_context()
        
        data = {
            "analysis_timestamp": self.analysis_time.isoformat(),
            "dao_tokens_overview": [],
            "bio_lp_support": [],
            "pool_performance": [],
            "position_details": [],
            "market_metrics": {},
            "market_context": self.market_context,
            "external_validation": {}
        }
        
        try:
            # 1. DAO Tokens Dashboard - –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –∏ —Ç—Ä–µ–Ω–¥—ã
            print("   üìà –ü–æ–ª—É—á–∞—é DAO Tokens Dashboard...")
            dao_dashboard = self.supabase.client.table('dao_tokens_dashboard').select('*').execute()
            
            if dao_dashboard.data:
                data["dao_tokens_overview"] = dao_dashboard.data
                print(f"     ‚úÖ {len(dao_dashboard.data)} —Ç–æ–∫–µ–Ω–æ–≤ —Å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏")
                
                # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ç–æ–∫–µ–Ω–æ–≤ —á–µ—Ä–µ–∑ –≤–Ω–µ—à–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
                data["external_validation"] = await self.validate_tokens_externally(dao_dashboard.data)
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                bio_token = next((t for t in dao_dashboard.data if 'BIO' in t.get('Token', '')), None)
                if bio_token:
                    data["market_metrics"]["bio_price"] = bio_token.get('Price')
                    data["market_metrics"]["bio_fdv"] = bio_token.get('FDV')
                    data["market_metrics"]["bio_24h_change"] = bio_token.get('24h Œî')
                    data["market_metrics"]["bio_7d_change"] = bio_token.get('7d Œî')
            
            # 2. Bio DAO LP Support - —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ LP
            print("   üß¨ –ü–æ–ª—É—á–∞—é Bio DAO LP Support...")
            bio_support = self.supabase.client.table('bio_dao_lp_support').select('*').execute()
            
            if bio_support.data:
                data["bio_lp_support"] = bio_support.data
                print(f"     ‚úÖ {len(bio_support.data)} –∑–∞–ø–∏—Å–µ–π –ø–æ BIO LP –ø–æ–¥–¥–µ—Ä–∂–∫–µ")
                
                # –£–ª—É—á—à–µ–Ω–Ω—ã–π —Ä–∞—Å—á–µ—Ç LP coverage —Å —á–µ—Ç–∫–æ–π –ª–æ–≥–∏–∫–æ–π 1% –æ—Ç FDV
                total_current = 0
                total_target_calculated = 0
                total_target_from_db = 0
                lp_coverage_by_chain = {}
                
                for item in bio_support.data:
                    token_symbol = item.get('token_symbol', '')
                    network = item.get('network', '')
                    fdv = float(item.get('token_fdv_usd', 0) or 0)
                    current_lp = float(item.get('our_position_value_usd', 0) or 0)
                    target_from_db = float(item.get('target_lp_value_usd', 0) or 0)
                    
                    # –ù–û–í–ê–Ø –õ–û–ì–ò–ö–ê: Target LP = 1% –æ—Ç FDV —Ç–æ–∫–µ–Ω–∞ –Ω–∞ —á–µ–π–Ω
                    target_calculated = fdv * 0.01  # 1% –æ—Ç FDV
                    
                    total_current += current_lp
                    total_target_calculated += target_calculated
                    total_target_from_db += target_from_db
                    
                    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —á–µ–π–Ω–∞–º –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
                    chain_key = network
                    if chain_key not in lp_coverage_by_chain:
                        lp_coverage_by_chain[chain_key] = {
                            'tokens': [],
                            'total_fdv': 0,
                            'total_target_lp': 0,
                            'total_current_lp': 0,
                            'coverage_ratio': 0
                        }
                    
                    chain_data = lp_coverage_by_chain[chain_key]
                    chain_data['tokens'].append({
                        'symbol': token_symbol,
                        'fdv': fdv,
                        'target_lp': target_calculated,
                        'current_lp': current_lp,
                        'coverage': (current_lp / target_calculated * 100) if target_calculated > 0 else 0
                    })
                    chain_data['total_fdv'] += fdv
                    chain_data['total_target_lp'] += target_calculated
                    chain_data['total_current_lp'] += current_lp
                
                # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º coverage –ø–æ —á–µ–π–Ω–∞–º
                for chain_key in lp_coverage_by_chain:
                    chain_data = lp_coverage_by_chain[chain_key]
                    chain_data['coverage_ratio'] = (
                        chain_data['total_current_lp'] / chain_data['total_target_lp'] * 100
                    ) if chain_data['total_target_lp'] > 0 else 0
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–µ —Ä–∞—Å—á–µ—Ç—ã
                total_gap = total_target_calculated - total_current
                
                data["market_metrics"]["total_target_lp"] = total_target_calculated
                data["market_metrics"]["total_current_lp"] = total_current  
                data["market_metrics"]["total_lp_gap"] = total_gap
                data["market_metrics"]["lp_coverage_ratio"] = (total_current / total_target_calculated * 100) if total_target_calculated > 0 else 0
                data["market_metrics"]["lp_coverage_by_chain"] = lp_coverage_by_chain
                data["market_metrics"]["target_lp_logic"] = "1% –æ—Ç FDV —Ç–æ–∫–µ–Ω–∞ –Ω–∞ —á–µ–π–Ω"
                
                print(f"     üìä Target LP (1% FDV): ${total_target_calculated:,.0f}")
                print(f"     üí∞ Current LP: ${total_current:,.0f}")
                print(f"     üìà Coverage: {(total_current / total_target_calculated * 100) if total_target_calculated > 0 else 0:.1f}%")
            
            # 3. Pool Performance - –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–Ω–∞–ø—à–æ—Ç—ã –≤—Å–µ—Ö –ø—É–ª–æ–≤
            print("   üèä –ü–æ–ª—É—á–∞—é –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ Pool snapshots...")
            pools = self.supabase.client.table('lp_pool_snapshots').select('*').order(
                'created_at', desc=True
            ).execute()
            
            if pools.data:
                # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–Ω–∞–ø—à–æ—Ç –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—É–ª–∞
                latest_pools = {}
                for pool in pools.data:
                    key = f"{pool['pool_address']}_{pool['network']}"
                    if key not in latest_pools:
                        latest_pools[key] = pool
                
                # –£–õ–£–ß–®–ï–ù–ù–ê–Ø –§–ò–õ–¨–¢–†–ê–¶–ò–Ø: –≤–∫–ª—é—á–∞–µ–º –ø—É–ª—ã —Å TVL > 0 –¥–∞–∂–µ –µ—Å–ª–∏ volume = 0
                # (–ø–æ—Å–ª–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π TVL –º–Ω–æ–≥–∏–µ –ø—É–ª—ã –ø–æ–ª—É—á–∏–ª–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è)
                active_pools = []
                inactive_pools = []
                
                for pool in latest_pools.values():
                    volume = pool.get('volume_24h_usd', 0) or 0
                    tvl = pool.get('tvl_usd', 0) or 0
                    
                    # –ê–∫—Ç–∏–≤–Ω—ã–π –ø—É–ª: –µ—Å—Ç—å –æ–±—ä–µ–º –ò–õ–ò –µ—Å—Ç—å –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–∞—è –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å
                    if volume > 0 or tvl > 1000:  # TVL > $1k —Å—á–∏—Ç–∞–µ–º –∑–Ω–∞—á–∏–º—ã–º
                        active_pools.append(pool)
                    else:
                        inactive_pools.append(pool)
                
                data["pool_performance"] = active_pools
                print(f"     ‚úÖ {len(active_pools)} –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø—É–ª–æ–≤ (volume > $0 OR TVL > $1k)")
                print(f"     ‚ö†Ô∏è {len(inactive_pools)} –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã—Ö –ø—É–ª–æ–≤ –∏—Å–∫–ª—é—á–µ–Ω—ã")
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º
                volume_pools = len([p for p in active_pools if p.get('volume_24h_usd', 0) > 0])
                tvl_only_pools = len([p for p in active_pools if p.get('volume_24h_usd', 0) == 0 and p.get('tvl_usd', 0) > 1000])
                print(f"     üìä –ò–∑ –Ω–∏—Ö: {volume_pools} —Å –æ–±—ä–µ–º–æ–º, {tvl_only_pools} —Ç–æ–ª—å–∫–æ —Å TVL")
            
            # 4. Position Details - –Ω–∞—à–∏ —Ç–µ–∫—É—â–∏–µ –ø–æ–∑–∏—Ü–∏–∏
            print("   üìç –ü–æ–ª—É—á–∞—é –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ Position snapshots...")
            positions = self.supabase.client.table('lp_position_snapshots').select('*').gt(
                'position_value_usd', 0
            ).order('created_at', desc=True).execute()
            
            if positions.data:
                # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–Ω–∞–ø—à–æ—Ç –¥–ª—è –∫–∞–∂–¥–æ–π –ø–æ–∑–∏—Ü–∏–∏
                latest_positions = {}
                for pos in positions.data:
                    key = pos['position_mint']
                    if key not in latest_positions:
                        latest_positions[key] = pos
                
                data["position_details"] = list(latest_positions.values())
                print(f"     ‚úÖ {len(latest_positions)} –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π")
                
                # –°—á–∏—Ç–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –ø–æ–∑–∏—Ü–∏–π
                total_pos_value = sum(float(pos.get('position_value_usd', 0)) for pos in latest_positions.values())
                in_range_count = sum(1 for pos in latest_positions.values() if pos.get('in_range'))
                total_fees = sum(float(pos.get('fees_usd', 0) or 0) for pos in latest_positions.values())
                
                data["market_metrics"]["total_position_value"] = total_pos_value
                data["market_metrics"]["in_range_positions"] = in_range_count
                data["market_metrics"]["total_positions"] = len(latest_positions)
                data["market_metrics"]["total_accumulated_fees"] = total_fees
                data["market_metrics"]["in_range_ratio"] = (in_range_count / len(latest_positions) * 100) if latest_positions else 0
            
            print(f"‚úÖ –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ–±—Ä–∞–Ω—ã:")
            print(f"   üìà {len(data['dao_tokens_overview'])} —Ç–æ–∫–µ–Ω–æ–≤")
            print(f"   üß¨ {len(data['bio_lp_support'])} BIO LP –∑–∞–ø–∏—Å–µ–π") 
            print(f"   üèä {len(data['pool_performance'])} –ø—É–ª–æ–≤")
            print(f"   üìç {len(data['position_details'])} –ø–æ–∑–∏—Ü–∏–π")
            
            return data
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö: {e}")
            raise
    
    def _format_lp_intelligence_prompt(self, data: Dict[str, Any]) -> str:
        """–°–æ–∑–¥–∞–µ—Ç —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è LP Management –∞–Ω–∞–ª–∏–∑–∞"""
        
        prompt = f"""LP MANAGEMENT & MARKET MAKING INTELLIGENCE REPORT
Analysis Time: {datetime.utcnow().strftime('%Y-%m-%d %H:%M UTC')}
Data Source: Real-time Supabase snapshots

=== EXECUTIVE SUMMARY ===
Total Tokens Monitored: {len(data['dao_tokens_overview'])}
Active LP Positions: {data['market_metrics'].get('total_positions', 0)}
In-Range Ratio: {data['market_metrics'].get('in_range_ratio', 0):.1f}%
Current LP Value: ${data['market_metrics'].get('total_position_value', 0):,.2f}
Total Accumulated Fees: ${data['market_metrics'].get('total_accumulated_fees', 0):,.2f}

=== BIO TOKEN MARKET STATE ===
"""
        
        # BIO –º–µ—Ç—Ä–∏–∫–∏
        bio_price = data['market_metrics'].get('bio_price')
        bio_fdv = data['market_metrics'].get('bio_fdv')
        bio_24h = data['market_metrics'].get('bio_24h_change')
        bio_7d = data['market_metrics'].get('bio_7d_change')
        
        if bio_price:
            prompt += f"Current Price: ${bio_price}\n"
            prompt += f"FDV: ${bio_fdv:,.0f}\n" if bio_fdv else "FDV: N/A\n"
            prompt += f"24h Change: {bio_24h}%\n" if bio_24h else ""
            prompt += f"7d Change: {bio_7d}%\n" if bio_7d else ""
        
        # LP Coverage –∞–Ω–∞–ª–∏–∑
        target_lp = data['market_metrics'].get('total_target_lp', 0)
        current_lp = data['market_metrics'].get('total_current_lp', 0)
        lp_gap = data['market_metrics'].get('total_lp_gap', 0)
        coverage = data['market_metrics'].get('lp_coverage_ratio', 0)
        coverage_by_chain = data['market_metrics'].get('lp_coverage_by_chain', {})
        
        prompt += f"\n=== LP COVERAGE ANALYSIS ===\n"
        prompt += f"TARGET LIQUIDITY LOGIC: {data['market_metrics'].get('target_lp_logic', 'Not specified')}\n"
        prompt += f"‚Ä¢ Target LP Value: ${target_lp:,.2f} (1% –æ—Ç –æ–±—â–µ–≥–æ FDV —Ç–æ–∫–µ–Ω–æ–≤)\n"
        prompt += f"‚Ä¢ Current LP Value: ${current_lp:,.2f}\n"
        prompt += f"‚Ä¢ LP Gap: ${lp_gap:,.2f}\n"
        prompt += f"‚Ä¢ Overall Coverage: {coverage:.1f}%\n\n"
        
        # –î–µ—Ç–∞–ª—å–Ω–∞—è —Ä–∞–∑–±–∏–≤–∫–∞ –ø–æ —á–µ–π–Ω–∞–º
        prompt += "COVERAGE BY BLOCKCHAIN:\n"
        for chain, chain_data in coverage_by_chain.items():
            prompt += f"\n{chain.upper()}:\n"
            prompt += f"  Total FDV: ${chain_data['total_fdv']:,.0f}\n"
            prompt += f"  Target LP (1%): ${chain_data['total_target_lp']:,.0f}\n"
            prompt += f"  Current LP: ${chain_data['total_current_lp']:,.0f}\n"
            prompt += f"  Coverage: {chain_data['coverage_ratio']:.1f}%\n"
            
            # –¢–æ–ø-3 —Ç–æ–∫–µ–Ω–∞ –ø–æ coverage
            tokens_by_coverage = sorted(chain_data['tokens'], key=lambda x: x['coverage'], reverse=True)
            prompt += f"  Top tokens by coverage:\n"
            for i, token in enumerate(tokens_by_coverage[:3]):
                prompt += f"    {i+1}. {token['symbol']}: {token['coverage']:.1f}% (${token['current_lp']:,.0f}/${token['target_lp']:,.0f})\n"
        
        # –¢–æ–ø —Ç–æ–∫–µ–Ω—ã –ø–æ FDV –∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è–º
        # –†—ã–Ω–æ—á–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        market_ctx = data.get('market_context', {})
        if any(market_ctx.values()):
            prompt += f"\n=== MARKET CONTEXT ===\n"
            if market_ctx.get('sol_price'):
                prompt += f"SOL: ${market_ctx['sol_price']:.2f} ({market_ctx.get('sol_24h_change', 0):+.2f}% 24h)\n"
            if market_ctx.get('eth_price'):
                prompt += f"ETH: ${market_ctx['eth_price']:.2f} ({market_ctx.get('eth_24h_change', 0):+.2f}% 24h)\n"
            if market_ctx.get('btc_price'):
                prompt += f"BTC: ${market_ctx['btc_price']:.2f} ({market_ctx.get('btc_24h_change', 0):+.2f}% 24h)\n"
        
        # –í–Ω–µ—à–Ω—è—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
        ext_validation = data.get('external_validation', {})
        if ext_validation:
            prompt += f"\n=== EXTERNAL VALIDATION (DexScreener) ===\n"
            summary = ext_validation.get('validation_summary', {})
            prompt += f"Ecosystem Health Score: {summary.get('health_score', 0)}/100\n"
            
            missing = ext_validation.get('missing_listings', [])
            if missing:
                prompt += f"\u26a0\ufe0f Missing Listings ({len(missing)}): "
                prompt += ", ".join([m['token'] for m in missing]) + "\n"
            
            price_diffs = ext_validation.get('price_differences', [])
            if price_diffs:
                prompt += f"\u26a0\ufe0f Price Discrepancies ({len(price_diffs)}): "
                for diff in price_diffs:
                    prompt += f"{diff['token']} ({diff['difference_pct']:.1f}% diff), "
                prompt = prompt.rstrip(', ') + "\n"
        
        prompt += f"\n=== TOKEN PERFORMANCE MATRIX ===\n"
        sorted_tokens = sorted(data['dao_tokens_overview'], 
                             key=lambda x: float(x.get('FDV', 0) or 0), reverse=True)
        
        for token in sorted_tokens[:10]:  # –¢–æ–ø 10
            symbol = token.get('Token', 'Unknown')
            fdv = float(token.get('FDV', 0) or 0)
            change_24h = token.get('24h Œî', 'N/A')
            tvl = float(token.get('TVL (all pools)', 0) or 0)
            fdv_tvl_ratio = float(token.get('FDV/TVL', 0) or 0)
            
            prompt += f"{symbol}: FDV ${fdv:,.0f}, 24h {change_24h}%, TVL ${tvl:,.0f}, FDV/TVL {fdv_tvl_ratio:.1f}x\n"
        
        # –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è BIO LP –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –ø–æ —Å–µ—Ç—è–º
        prompt += f"\n=== BIO LP SUPPORT BY NETWORK ===\n"
        networks = {}
        for item in data['bio_lp_support']:
            network = item.get('network_display', 'Unknown')
            if network not in networks:
                networks[network] = []
            networks[network].append(item)
        
        for network, items in networks.items():
            prompt += f"\n{network}:\n"
            for item in items:
                symbol = item.get('token_symbol', 'Unknown')
                target = float(item.get('target_lp_value_usd', 0) or 0)
                current = float(item.get('our_position_value_usd', 0) or 0)
                gap = float(item.get('lp_gap_usd', 0) or 0)
                tvl = float(item.get('tvl_usd', 0) or 0)
                
                coverage_pct = (current / target * 100) if target > 0 else 0
                prompt += f"  {symbol}: Target ${target:,.0f}, Current ${current:,.0f}, Gap ${gap:,.0f} ({coverage_pct:.1f}% coverage), Pool TVL ${tvl:,.0f}\n"
        
        # Pool Performance –¥–µ—Ç–∞–ª–∏
        prompt += f"\n=== POOL PERFORMANCE ANALYSIS ===\n"
        bio_pools = [p for p in data['pool_performance'] if 'BIO' in p.get('pool_name', '')]
        
        for pool in bio_pools:
            name = pool.get('pool_name', 'Unknown')
            network = pool.get('network', 'Unknown')
            tvl = float(pool.get('tvl_usd', 0) or 0)
            volume_24h = float(pool.get('volume_24h_usd', 0) or 0)
            price_change = pool.get('price_change_24h_percent', 'N/A')
            tvl_change = pool.get('tvl_change_percent', 'N/A')
            in_range_pos = pool.get('in_range_positions', 0)
            total_pos = pool.get('total_positions', 0)
            
            prompt += f"{name} ({network}):\n"
            prompt += f"  TVL: ${tvl:,.0f} (24h change: {tvl_change}%)\n"
            prompt += f"  Volume 24h: ${volume_24h:,.0f}\n"
            prompt += f"  Price change 24h: {price_change}%\n"
            prompt += f"  Positions: {in_range_pos}/{total_pos} in-range\n"
        
        # –ù–∞—à–∏ –ø–æ–∑–∏—Ü–∏–∏ –ø–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        prompt += f"\n=== OUR POSITION EFFICIENCY ANALYSIS ===\n"
        bio_positions = [p for p in data['position_details'] if 'BIO' in p.get('pool_name', '')]
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å—Ç–æ–∏–º–æ—Å—Ç–∏
        bio_positions.sort(key=lambda x: float(x.get('position_value_usd', 0)), reverse=True)
        
        for pos in bio_positions[:15]:  # –¢–æ–ø 15 –ø–æ–∑–∏—Ü–∏–π
            pool = pos.get('pool_name', 'Unknown')
            network = pos.get('network', 'Unknown')
            value = float(pos.get('position_value_usd', 0))
            fees = float(pos.get('fees_usd', 0) or 0)
            in_range = pos.get('in_range', False)
            age = pos.get('position_age_days', 0)
            health_score = pos.get('position_health_score', 'N/A')
            il_pct = pos.get('impermanent_loss_pct', 'N/A')
            
            status = "üü¢ IN-RANGE" if in_range else "üî¥ OUT-RANGE"
            prompt += f"{pool} ({network}): ${value:,.0f}, Fees ${fees:,.2f}, {status}, Age {age}d, Health {health_score}, IL {il_pct}%\n"
        
        return prompt
    
    def _create_grok_prompt(self, data: Dict[str, Any]) -> tuple:
        """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è Grok 4 —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ LP —Å—Ç—Ä–∞—Ç–µ–≥–∏—é"""
        
        system_prompt = """–¢—ã —Å—Ç—Ä–∞—Ç–µ–≥ —ç–∫–æ—Å–∏—Å—Ç–µ–º—ã Bio Protocol. –ë—É–¥—å –ö–†–ê–¢–ö–ò–ú –∏ –ù–ê–ü–†–ê–í–õ–ï–ù–ù–´–ú –ù–ê –î–ï–ô–°–¢–í–ò–Ø.

–ö–û–ù–¢–ï–ö–°–¢:
- BIO - –æ—Å–Ω–æ–≤–Ω–∞—è –ø–∞—Ä–∞ –¥–ª—è –≤—Å–µ—Ö bioDAO —Ç–æ–∫–µ–Ω–æ–≤
- –î–æ—Å—Ç—É–ø–Ω–æ 830M BIO –∏–∑ —ç–∫–æ—Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ —Ñ–æ–Ω–¥–∞ (~$6.8M –ø–æ —Ç–µ–∫—É—â–∏–º —Ü–µ–Ω–∞–º)
- –¶–µ–ª—å: 1% FDV –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏ –Ω–∞ —Ç–æ–∫–µ–Ω –Ω–∞ —Å–µ—Ç—å
- –ó–∞–¥–∞—á–∞: –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—Ç–∏—Ç—å –ø–æ—è–≤–ª–µ–Ω–∏–µ "–º–µ—Ä—Ç–≤—ã—Ö" –∏–ª–∏ –Ω–µ—Ä–∞–±–æ—Ç–∞—é—â–∏—Ö —Ç–æ–∫–µ–Ω–æ–≤

–¢–í–û–Ø –†–û–õ–¨:
- –û–ø—Ä–µ–¥–µ–ª–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–µ–ª—ã LP –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ $ —Å—É–º–º—ã
- –ü—Ä–µ–¥–ª–æ–∂–∏ —Å–∏—Å—Ç–µ–º—ã –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏/–º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
- –°–æ—Å—Ä–µ–¥–æ—Ç–æ—á—å—Å—è –Ω–∞ –Ω–µ–º–µ–¥–ª–µ–Ω–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏—è—Ö, –∞ –Ω–µ –Ω–∞ —Ç–µ–æ—Ä–∏–∏

–¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö –û–¢–í–ï–¢–£:
- –ò—Å–ø–æ–ª—å–∑—É–π —Å–ø–∏—Å–∫–∏ –∏ —Ü–∏—Ñ—Ä—ã
- –£–∫–∞–∑—ã–≤–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ $ —Å—É–º–º—ã –∏–∑ BIO —Ñ–æ–Ω–¥–∞
- –ö–∞–∂–¥–∞—è —Å–µ–∫—Ü–∏—è –º–∞–∫—Å–∏–º—É–º 200 —Å–ª–æ–≤
- –ù–∏–∫–∞–∫–∏—Ö –¥–ª–∏–Ω–Ω—ã—Ö –æ–±—ä—è—Å–Ω–µ–Ω–∏–π –∏ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤—ã—Ö —Ä–µ—á–µ–π
- –§–æ–∫—É—Å –Ω–∞ —Ç–æ–º, —á—Ç–æ –¥–µ–ª–∞—Ç—å –ù–ê –≠–¢–û–ô –ù–ï–î–ï–õ–ï

–ë—É–¥—å –ø—Ä—è–º—ã–º, –ø—Ä–∞–∫—Ç–∏—á–Ω—ã–º –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–º."""

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è Grok
        formatted_data = self._format_lp_intelligence_prompt(data)
        
        user_prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–∞–Ω–Ω—ã–µ —ç–∫–æ—Å–∏—Å—Ç–µ–º—ã Bio Protocol –∏ –¥–∞–π –ö–†–ê–¢–ö–ò–ï —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:

=== –î–ê–ù–ù–´–ï ===
{formatted_data}

=== –¢–†–ï–ë–£–ï–ú–´–ô –ê–ù–ê–õ–ò–ó (–ö–†–ê–¢–ö–û –ò –ö–û–ù–ö–†–ï–¢–ù–û) ===

üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ü–†–û–ë–õ–ï–ú–´:
- –ö–∞–∫–∏–µ —Ç–æ–∫–µ–Ω—ã –∏–º–µ—é—Ç –ø–æ–∫—Ä—ã—Ç–∏–µ LP <50%? –°–ø–∏—Å–æ–∫ —Å —Ä–∞–∑—Ä—ã–≤–∞–º–∏ –≤ $.
- –ö–∞–∫–∏–µ —Ç–æ–∫–µ–Ω—ã –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–∞ DexScreener/–æ—Å–Ω–æ–≤–Ω—ã—Ö DEX?
- –ü–æ–∑–∏—Ü–∏–∏ —Å –≤—ã—Å–æ–∫–∏–º —Ä–∏—Å–∫–æ–º IL –∏–ª–∏ –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞?

üí∞ –ù–ï–ú–ï–î–õ–ï–ù–ù–´–ï –î–ï–ô–°–¢–í–ò–Ø (—ç—Ç–∞ –Ω–µ–¥–µ–ª—è):
- –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ $ —Å—É–º–º—ã –¥–ª—è –≤—ã–¥–µ–ª–µ–Ω–∏—è –∏–∑ —Ñ–æ–Ω–¥–∞ 830M BIO
- –ö–∞–∫–∏–µ –ø—É–ª—ã –Ω—É–∂–¥–∞—é—Ç—Å—è –≤ —Å—Ä–æ—á–Ω–æ–º –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏?
- –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã: 1-3 —Å–∞–º—ã—Ö –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏—è

ü§ñ –í–û–ó–ú–û–ñ–ù–û–°–¢–ò –ê–í–¢–û–ú–ê–¢–ò–ó–ê–¶–ò–ò:
- –ü—Ä–æ—Å—Ç—ã–µ —Å–∫—Ä–∏–ø—Ç—ã –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞/—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏
- –ü–æ—Ä–æ–≥–∏ –∞–ª–µ—Ä—Ç–æ–≤ (—Ü–µ–Ω–∞, –æ–±—ä–µ–º, –ø–æ–∫—Ä—ã—Ç–∏–µ)
- –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞—Ä–±–∏—Ç—Ä–∞–∂–∞ –º–µ–∂–¥—É —Å–µ—Ç—è–º–∏

üìä –ú–ï–¢–†–ò–ö–ò –£–°–ü–ï–•–ê:
- –¶–µ–ª–µ–≤–æ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ % –ø–æ —Å–µ—Ç—è–º
- –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è –æ–±—ä–µ–º/–ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è
- –ì—Ä–∞—Ñ–∏–∫ —Å–ª–µ–¥—É—é—â–µ–≥–æ –æ–±–∑–æ—Ä–∞

–§–û–†–ú–ê–¢: –ò—Å–ø–æ–ª—å–∑—É–π —Å–ø–∏—Å–∫–∏, —Ü–∏—Ñ—Ä—ã –∏ —Ç–∞–±–ª–∏—Ü—ã. –ù–ò–ö–ê–ö–ò–• –¥–ª–∏–Ω–Ω—ã—Ö –æ–±—ä—è—Å–Ω–µ–Ω–∏–π.
–§–û–ö–£–°: –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –¥–µ–π—Å—Ç–≤–∏—è —Å $ —Å—É–º–º–∞–º–∏ –∏ –¥–µ–¥–ª–∞–π–Ω–∞–º–∏.
–î–õ–ò–ù–ê: –ú–∞–∫—Å–∏–º—É–º 300 —Å–ª–æ–≤ –Ω–∞ —Å–µ–∫—Ü–∏—é."""

        return system_prompt, user_prompt
    
    async def get_grok_lp_analysis(self, data: Dict[str, Any]) -> Optional[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π LP –∞–Ω–∞–ª–∏–∑ –æ—Ç Grok 4"""
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        data_prompt = self._format_lp_intelligence_prompt(data)
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç—ã
        system_prompt, user_prompt = self._create_grok_prompt(data)
        
        headers = {
            "Authorization": f"Bearer {GROK_API_KEY}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": "grok-4-0709",
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "max_tokens": 3000,
            "temperature": 0.1
        }
        
        try:
            print("üöÄ –û—Ç–ø—Ä–∞–≤–ª—è—é –¥–∞–Ω–Ω—ã–µ –≤ Grok 4 –¥–ª—è LP –∞–Ω–∞–ª–∏–∑–∞...")
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    GROK_API_URL,
                    headers=headers,
                    json=payload,
                    timeout=150
                )
                
                if response.status_code == 200:
                    data = response.json()
                    if "choices" in data and len(data["choices"]) > 0:
                        analysis = data["choices"][0]["message"]["content"]
                        print(f"‚úÖ Grok 4 LP –∞–Ω–∞–ª–∏–∑ –ø–æ–ª—É—á–µ–Ω ({len(analysis)} —Å–∏–º–≤–æ–ª–æ–≤)")
                        return analysis
                    
                print(f"‚ùå Grok –æ—à–∏–±–∫–∞: {response.status_code} - {response.text}")
                return None
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ Grok –∑–∞–ø—Ä–æ—Å–∞: {e}")
            return None
    
    async def get_gpt_o3_analysis(self, data: Dict[str, Any]) -> Optional[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –æ—Ç GPT o3"""
        
        if not OPENAI_API_KEY:
            return None
            
        data_prompt = self._format_lp_intelligence_prompt(data)
        
        headers = {
            "Authorization": f"Bearer {OPENAI_API_KEY}",
            "Content-Type": "application/json"
        }
        
        system_prompt = """You are an elite quantitative DeFi analyst with advanced reasoning capabilities specializing in Bio Protocol ecosystem analysis.

ANALYTICAL FRAMEWORK:
- Target Liquidity Model: 1% of token FDV per blockchain provides optimal institutional trading depth
- Coverage Ratios: <50% urgent gaps, 50-100% healthy, >150% potential over-allocation
- LP Efficiency Metrics: Focus on fees/capital ratio, impermanent loss minimization, volume/liquidity ratio

Use step-by-step reasoning to provide quantitative insights on:
1. LP capital allocation efficiency across chains (Solana, Ethereum, Base)
2. Mathematical optimization of position ranges and sizes
3. Risk-adjusted return calculations for each LP pair
4. Cross-chain arbitrage opportunities and optimal execution

Provide mathematical models, specific dollar recommendations, and quantified risk assessments."""
        
        payload = {
            "model": "o3",
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"Analyze this LP portfolio data and provide quantitative insights:\n\n{data_prompt}"}
            ],
            "max_completion_tokens": 2000
        }
        
        try:
            print("ü§ñ –û—Ç–ø—Ä–∞–≤–ª—è—é –¥–∞–Ω–Ω—ã–µ –≤ GPT o3 –¥–ª—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞...")
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    OPENAI_API_URL,
                    headers=headers,
                    json=payload,
                    timeout=120
                )
                
                if response.status_code == 200:
                    data = response.json()
                    if "choices" in data and len(data["choices"]) > 0:
                        analysis = data["choices"][0]["message"]["content"]
                        print(f"‚úÖ GPT o3 –∞–Ω–∞–ª–∏–∑ –ø–æ–ª—É—á–µ–Ω ({len(analysis)} —Å–∏–º–≤–æ–ª–æ–≤)")
                        return analysis
                    
                print(f"‚ùå GPT o3 –æ—à–∏–±–∫–∞: {response.status_code} - {response.text}")
                return None
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ GPT o3 –∑–∞–ø—Ä–æ—Å–∞: {e}")
            return None
    
    async def send_fallback_report(self, raw_data: Dict) -> bool:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –±–∞–∑–æ–≤—ã–π –æ—Ç—á–µ—Ç —Å –¥–∞–Ω–Ω—ã–º–∏ –µ—Å–ª–∏ AI –∞–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"""
        
        try:
            telegram = TelegramSender()
            
            # –ë–∞–∑–æ–≤—ã–π –æ—Ç—á–µ—Ç —Å –∫–ª—é—á–µ–≤—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
            fallback_report = f"""üß¨ <b>–û–¢–ß–ï–¢ BIO PROTOCOL LP</b>
üìÖ {self.analysis_time.strftime('%d.%m.%Y %H:%M UTC')}
‚ö†Ô∏è <i>AI –∞–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø–æ–∫–∞–∑—ã–≤–∞—é –±–∞–∑–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ</i>

üí∞ <b>–ü–û–†–¢–§–ï–õ–¨</b>
‚Ä¢ –û–±—â–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å: <b>${raw_data['market_metrics'].get('total_position_value', 0):,.0f}</b>
‚Ä¢ –ê–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π: <b>{raw_data['market_metrics'].get('total_positions', 0)}</b>
‚Ä¢ –í –¥–∏–∞–ø–∞–∑–æ–Ω–µ: <b>{raw_data['market_metrics'].get('in_range_ratio', 0):.1f}%</b>
‚Ä¢ –ù–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ –∫–æ–º–∏—Å—Å–∏–∏: <b>${raw_data['market_metrics'].get('total_accumulated_fees', 0):,.2f}</b>

üéØ <b>–ü–û–ö–†–´–¢–ò–ï LP</b>
‚Ä¢ –¶–µ–ª–µ–≤–æ–π LP: <b>${raw_data['market_metrics'].get('total_target_lp', 0):,.0f}</b>
‚Ä¢ –¢–µ–∫—É—â–∏–π LP: <b>${raw_data['market_metrics'].get('total_current_lp', 0):,.0f}</b>
‚Ä¢ –ü–æ–∫—Ä—ã—Ç–∏–µ: <b>{raw_data['market_metrics'].get('lp_coverage_ratio', 0):.1f}%</b>
‚Ä¢ –†–∞–∑—Ä—ã–≤: <b>${raw_data['market_metrics'].get('total_lp_gap', 0):,.0f}</b>

üìä <b>–¢–û–ö–ï–ù BIO</b>
‚Ä¢ –¶–µ–Ω–∞: <b>${raw_data['market_metrics'].get('bio_price', 0):.6f}</b>
‚Ä¢ –ò–∑–º–µ–Ω–µ–Ω–∏–µ 24—á: <b>{raw_data['market_metrics'].get('bio_24h_change', 0):+.2f}%</b>
‚Ä¢ FDV: <b>${raw_data['market_metrics'].get('bio_fdv', 0):,.0f}</b>

üìà <b>–ê–ö–¢–ò–í–ù–´–ï –ü–£–õ–´</b>
‚Ä¢ –í—Å–µ–≥–æ: <b>{len(raw_data['pool_performance'])}</b> –ø—É–ª–æ–≤
‚Ä¢ –°–µ—Ç–∏: Solana, Ethereum, Base

<i>–î–ª—è –ø–æ–ª–Ω–æ–≥–æ AI –∞–Ω–∞–ª–∏–∑–∞ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É</i>"""
            
            await telegram.send_message(fallback_report)
            print("‚úÖ Fallback –æ—Ç—á–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –≤ Telegram")
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ fallback –æ—Ç—á–µ—Ç–∞: {e}")
            return False
    
    async def send_telegram_report(self, grok_analysis: str, gpt_analysis: str, raw_data: Dict) -> bool:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∞–Ω–∞–ª–∏–∑ –≤ Telegram"""
        
        try:
            telegram = TelegramSender()
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –æ—Ç—á–µ—Ç–∞
            header = f"""üß¨ <b>BIO PROTOCOL LP INTELLIGENCE</b>
üìÖ {self.analysis_time.strftime('%d.%m.%Y %H:%M UTC')}
üí∞ Portfolio: <b>${raw_data['market_metrics'].get('total_position_value', 0):,.0f}</b>
üìç Positions: <b>{raw_data['market_metrics'].get('total_positions', 0)}</b> (In-range: <b>{raw_data['market_metrics'].get('in_range_ratio', 0):.1f}%</b>)
üéØ LP Coverage: <b>{raw_data['market_metrics'].get('lp_coverage_ratio', 0):.1f}%</b>
üí∏ LP Gap: <b>${raw_data['market_metrics'].get('total_lp_gap', 0):,.0f}</b>

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"""
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
            await telegram.send_message(header)
            await asyncio.sleep(1)
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∞–Ω–∞–ª–∏–∑ Grok
            if grok_analysis:
                grok_header = "üöÄ <b>GROK 4 LP STRATEGY ANALYSIS</b>"
                await telegram.send_message(grok_header)
                await asyncio.sleep(1)
                
                # –†–∞–∑–±–∏–≤–∞–µ–º –¥–ª–∏–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–∞ —á–∞—Å—Ç–∏ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ë–ï–ó HTML —Ä–∞–∑–º–µ—Ç–∫–∏
                analysis_parts = self._split_analysis_text(grok_analysis, 3000)
                for i, part in enumerate(analysis_parts):
                    await telegram.send_message(part, parse_mode=None)  # –ë–µ–∑ HTML
                    if i < len(analysis_parts) - 1:
                        await asyncio.sleep(2)
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∞–Ω–∞–ª–∏–∑ GPT
            if gpt_analysis:
                await asyncio.sleep(2)
                gpt_header = "ü§ñ <b>GPT O3 QUANTITATIVE ANALYSIS</b>"
                await telegram.send_message(gpt_header)
                await asyncio.sleep(1)
                
                # –†–∞–∑–±–∏–≤–∞–µ–º –¥–ª–∏–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–∞ —á–∞—Å—Ç–∏ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ë–ï–ó HTML —Ä–∞–∑–º–µ—Ç–∫–∏
                gpt_parts = self._split_analysis_text(gpt_analysis, 3000)
                for i, part in enumerate(gpt_parts):
                    await telegram.send_message(part, parse_mode=None)  # –ë–µ–∑ HTML
                    if i < len(gpt_parts) - 1:
                        await asyncio.sleep(2)
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            await asyncio.sleep(2)
            metrics_text = f"""üìä <b>KEY METRICS SUMMARY</b>
‚Ä¢ BIO Price: <b>${raw_data['market_metrics'].get('bio_price', 0):.6f}</b> ({raw_data['market_metrics'].get('bio_24h_change', 0):+.2f}% 24h)
‚Ä¢ BIO FDV: <b>${raw_data['market_metrics'].get('bio_fdv', 0):,.0f}</b>
‚Ä¢ Total Target LP: <b>${raw_data['market_metrics'].get('total_target_lp', 0):,.0f}</b>
‚Ä¢ Current LP: <b>${raw_data['market_metrics'].get('total_current_lp', 0):,.0f}</b>
‚Ä¢ Fees Accumulated: <b>${raw_data['market_metrics'].get('total_accumulated_fees', 0):,.2f}</b>"""
            
            await telegram.send_message(metrics_text)
            
            print("‚úÖ LP Intelligence –æ—Ç—á–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –≤ Telegram")
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Telegram: {e}")
            return False
    
    def _escape_html_chars(self, text: str) -> str:
        """–≠–∫—Ä–∞–Ω–∏—Ä—É–µ—Ç HTML —Å–∏–º–≤–æ–ª—ã –¥–ª—è Telegram"""
        if not text:
            return text
        # –ó–∞–º–µ–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã, —Å–æ—Ö—Ä–∞–Ω—è—è –±–∞–∑–æ–≤—É—é —Ä–∞–∑–º–µ—Ç–∫—É
        text = text.replace('&', '&amp;')
        text = text.replace('<', '&lt;')
        text = text.replace('>', '&gt;')
        # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ –≤ —Ç–µ–≥–∞—Ö
        import re
        text = re.sub(r'(?<!<[^>]*)\%(?![^<]*>)', ' percent', text)
        return text
    
    def _split_analysis_text(self, text: str, max_length: int) -> List[str]:
        """–†–∞–∑–±–∏–≤–∞–µ—Ç –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞ —á–∞—Å—Ç–∏ –¥–ª—è Telegram"""
        if len(text) <= max_length:
            return [text]
        
        parts = []
        current_part = ""
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ –∞–±–∑–∞—Ü–∞–º
        paragraphs = text.split('\n\n')
        
        for paragraph in paragraphs:
            # –ï—Å–ª–∏ –∞–±–∑–∞—Ü —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π, —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º
            if len(paragraph) > max_length:
                sentences = paragraph.split('. ')
                for sentence in sentences:
                    if len(current_part + sentence) > max_length:
                        if current_part:
                            parts.append(current_part.strip())
                            current_part = sentence + '. '
                        else:
                            # –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ, —Ä–∞–∑–±–∏–≤–∞–µ–º –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ
                            parts.append(sentence[:max_length-3] + "...")
                    else:
                        current_part += sentence + '. '
            else:
                if len(current_part + paragraph) > max_length:
                    if current_part:
                        parts.append(current_part.strip())
                        current_part = paragraph + '\n\n'
                    else:
                        parts.append(paragraph)
                else:
                    current_part += paragraph + '\n\n'
        
        if current_part.strip():
            parts.append(current_part.strip())
        
        return parts

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è LP –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞"""
    
    print("üß¨ BIO PROTOCOL LP INTELLIGENCE ANALYZER")
    print("=" * 60)
    print(f"‚è∞ –ó–∞–ø—É—Å–∫: {datetime.utcnow().strftime('%Y-%m-%d %H:%M UTC')}")
    print("üéØ –§–æ–∫—É—Å: LP Management & Market Making Optimization")
    
    analyzer = BioLPAnalyzer()
    
    try:
        # 1. –°–æ–±–∏—Ä–∞–µ–º –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        portfolio_data = await analyzer.collect_comprehensive_data()
        
        if not any([portfolio_data['dao_tokens_overview'], portfolio_data['bio_lp_support'], 
                   portfolio_data['position_details']]):
            print("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            return
        
        print(f"\nüöÄ –ó–∞–ø—É—Å–∫–∞—é AI –∞–Ω–∞–ª–∏–∑ –ø–æ—Ä—Ç—Ñ–µ–ª—è...")
        
        # 2. –ü–æ–ª—É—á–∞–µ–º –∞–Ω–∞–ª–∏–∑ —Ç–æ–ª—å–∫–æ –æ—Ç Grok (GPT o3 –≤—Ä–µ–º–µ–Ω–Ω–æ –∏—Å–∫–ª—é—á–µ–Ω)
        print("üìä –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–≤–æ–¥–∏—Ç—Å—è —Ç–æ–ª—å–∫–æ —á–µ—Ä–µ–∑ Grok 4...")
        grok_analysis = await analyzer.get_grok_lp_analysis(portfolio_data)
        
        # 3. –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        if grok_analysis:
            await analyzer.send_telegram_report(grok_analysis, None, portfolio_data)
            print("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω –∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –≤ Telegram")
        else:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –æ—Ç Grok")
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –±–∞–∑–æ–≤—ã–π –æ—Ç—á–µ—Ç —Å –¥–∞–Ω–Ω—ã–º–∏
            await analyzer.send_fallback_report(portfolio_data)
    
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main()) 