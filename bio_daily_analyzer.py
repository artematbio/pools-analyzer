#!/usr/bin/env python3
"""
Bio Daily Analyzer v2.0 - LP Management & Market Making Intelligence
–ï–∂–µ–¥–Ω–µ–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ LP –ø–æ–∑–∏—Ü–∏–π –∏ –ø–æ–≤—ã—à–µ–Ω–∏—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ —Ç–æ–∫–µ–Ω–æ–≤
"""

import os
import asyncio
import httpx
import json
from datetime import datetime, timedelta
from decimal import Decimal
from typing import Dict, List, Optional, Any
from database_handler import supabase_handler
from telegram_sender import TelegramSender

# API –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
GROK_API_KEY = os.getenv('GROK_API_KEY')

# API URLs
OPENAI_API_URL = "https://api.openai.com/v1/chat/completions"
GROK_API_URL = "https://api.x.ai/v1/chat/completions"

class BioLPAnalyzer:
    def __init__(self):
        self.supabase = supabase_handler
        self.analysis_time = datetime.utcnow()
        
    async def collect_comprehensive_data(self) -> Dict[str, Any]:
        """–°–æ–±–∏—Ä–∞–µ—Ç –ø–æ–ª–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è LP –∞–Ω–∞–ª–∏–∑–∞"""
        
        print("üìä –°–æ–±–∏—Ä–∞—é –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è LP –∞–Ω–∞–ª–∏–∑–∞...")
        print(f"‚è∞ –í—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞: {self.analysis_time.strftime('%Y-%m-%d %H:%M UTC')}")
        
        data = {
            "analysis_timestamp": self.analysis_time.isoformat(),
            "dao_tokens_overview": [],
            "bio_lp_support": [],
            "pool_performance": [],
            "position_details": [],
            "market_metrics": {}
        }
        
        try:
            # 1. DAO Tokens Dashboard - –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –∏ —Ç—Ä–µ–Ω–¥—ã
            print("   üìà –ü–æ–ª—É—á–∞—é DAO Tokens Dashboard...")
            dao_dashboard = self.supabase.client.table('dao_tokens_dashboard').select('*').execute()
            
            if dao_dashboard.data:
                data["dao_tokens_overview"] = dao_dashboard.data
                print(f"     ‚úÖ {len(dao_dashboard.data)} —Ç–æ–∫–µ–Ω–æ–≤ —Å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏")
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                bio_token = next((t for t in dao_dashboard.data if 'BIO' in t.get('Token', '')), None)
                if bio_token:
                    data["market_metrics"]["bio_price"] = bio_token.get('Price')
                    data["market_metrics"]["bio_fdv"] = bio_token.get('FDV')
                    data["market_metrics"]["bio_24h_change"] = bio_token.get('24h Œî')
                    data["market_metrics"]["bio_7d_change"] = bio_token.get('7d Œî')
            
            # 2. Bio DAO LP Support - —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ LP
            print("   üß¨ –ü–æ–ª—É—á–∞—é Bio DAO LP Support...")
            bio_support = self.supabase.client.table('bio_dao_lp_support').select('*').execute()
            
            if bio_support.data:
                data["bio_lp_support"] = bio_support.data
                print(f"     ‚úÖ {len(bio_support.data)} –∑–∞–ø–∏—Å–µ–π –ø–æ BIO LP –ø–æ–¥–¥–µ—Ä–∂–∫–µ")
                
                # –£–ª—É—á—à–µ–Ω–Ω—ã–π —Ä–∞—Å—á–µ—Ç LP coverage —Å —á–µ—Ç–∫–æ–π –ª–æ–≥–∏–∫–æ–π 1% –æ—Ç FDV
                total_current = 0
                total_target_calculated = 0
                total_target_from_db = 0
                lp_coverage_by_chain = {}
                
                for item in bio_support.data:
                    token_symbol = item.get('token_symbol', '')
                    network = item.get('network', '')
                    fdv = float(item.get('token_fdv_usd', 0) or 0)
                    current_lp = float(item.get('our_position_value_usd', 0) or 0)
                    target_from_db = float(item.get('target_lp_value_usd', 0) or 0)
                    
                    # –ù–û–í–ê–Ø –õ–û–ì–ò–ö–ê: Target LP = 1% –æ—Ç FDV —Ç–æ–∫–µ–Ω–∞ –Ω–∞ —á–µ–π–Ω
                    target_calculated = fdv * 0.01  # 1% –æ—Ç FDV
                    
                    total_current += current_lp
                    total_target_calculated += target_calculated
                    total_target_from_db += target_from_db
                    
                    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —á–µ–π–Ω–∞–º –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
                    chain_key = network
                    if chain_key not in lp_coverage_by_chain:
                        lp_coverage_by_chain[chain_key] = {
                            'tokens': [],
                            'total_fdv': 0,
                            'total_target_lp': 0,
                            'total_current_lp': 0,
                            'coverage_ratio': 0
                        }
                    
                    chain_data = lp_coverage_by_chain[chain_key]
                    chain_data['tokens'].append({
                        'symbol': token_symbol,
                        'fdv': fdv,
                        'target_lp': target_calculated,
                        'current_lp': current_lp,
                        'coverage': (current_lp / target_calculated * 100) if target_calculated > 0 else 0
                    })
                    chain_data['total_fdv'] += fdv
                    chain_data['total_target_lp'] += target_calculated
                    chain_data['total_current_lp'] += current_lp
                
                # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º coverage –ø–æ —á–µ–π–Ω–∞–º
                for chain_key in lp_coverage_by_chain:
                    chain_data = lp_coverage_by_chain[chain_key]
                    chain_data['coverage_ratio'] = (
                        chain_data['total_current_lp'] / chain_data['total_target_lp'] * 100
                    ) if chain_data['total_target_lp'] > 0 else 0
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–µ —Ä–∞—Å—á–µ—Ç—ã
                total_gap = total_target_calculated - total_current
                
                data["market_metrics"]["total_target_lp"] = total_target_calculated
                data["market_metrics"]["total_current_lp"] = total_current  
                data["market_metrics"]["total_lp_gap"] = total_gap
                data["market_metrics"]["lp_coverage_ratio"] = (total_current / total_target_calculated * 100) if total_target_calculated > 0 else 0
                data["market_metrics"]["lp_coverage_by_chain"] = lp_coverage_by_chain
                data["market_metrics"]["target_lp_logic"] = "1% –æ—Ç FDV —Ç–æ–∫–µ–Ω–∞ –Ω–∞ —á–µ–π–Ω"
                
                print(f"     üìä Target LP (1% FDV): ${total_target_calculated:,.0f}")
                print(f"     üí∞ Current LP: ${total_current:,.0f}")
                print(f"     üìà Coverage: {(total_current / total_target_calculated * 100) if total_target_calculated > 0 else 0:.1f}%")
            
            # 3. Pool Performance - –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–Ω–∞–ø—à–æ—Ç—ã –≤—Å–µ—Ö –ø—É–ª–æ–≤
            print("   üèä –ü–æ–ª—É—á–∞—é –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ Pool snapshots...")
            pools = self.supabase.client.table('lp_pool_snapshots').select('*').order(
                'created_at', desc=True
            ).execute()
            
            if pools.data:
                # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–Ω–∞–ø—à–æ—Ç –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—É–ª–∞
                latest_pools = {}
                for pool in pools.data:
                    key = f"{pool['pool_address']}_{pool['network']}"
                    if key not in latest_pools:
                        latest_pools[key] = pool
                
                # –ò–°–ö–õ–Æ–ß–ê–ï–ú –ü–£–õ–´ –° –ù–£–õ–ï–í–´–ú–ò –û–ë–™–ï–ú–ê–ú–ò –∏–∑ –∞–Ω–∞–ª–∏–∑–∞ (–ø—Ä–æ–±–ª–µ–º–∞ —Å Ethereum/Base)
                active_pools = [p for p in latest_pools.values() if p.get('volume_24h_usd', 0) > 0]
                inactive_pools = [p for p in latest_pools.values() if p.get('volume_24h_usd', 0) == 0]
                
                data["pool_performance"] = active_pools
                print(f"     ‚úÖ {len(active_pools)} –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø—É–ª–æ–≤ (–æ–±—ä–µ–º > $0)")
                print(f"     ‚ö†Ô∏è {len(inactive_pools)} –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã—Ö –ø—É–ª–æ–≤ –∏—Å–∫–ª—é—á–µ–Ω—ã –∏–∑ –∞–Ω–∞–ª–∏–∑–∞")
            
            # 4. Position Details - –Ω–∞—à–∏ —Ç–µ–∫—É—â–∏–µ –ø–æ–∑–∏—Ü–∏–∏
            print("   üìç –ü–æ–ª—É—á–∞—é –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ Position snapshots...")
            positions = self.supabase.client.table('lp_position_snapshots').select('*').gt(
                'position_value_usd', 0
            ).order('created_at', desc=True).execute()
            
            if positions.data:
                # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–Ω–∞–ø—à–æ—Ç –¥–ª—è –∫–∞–∂–¥–æ–π –ø–æ–∑–∏—Ü–∏–∏
                latest_positions = {}
                for pos in positions.data:
                    key = pos['position_mint']
                    if key not in latest_positions:
                        latest_positions[key] = pos
                
                data["position_details"] = list(latest_positions.values())
                print(f"     ‚úÖ {len(latest_positions)} –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π")
                
                # –°—á–∏—Ç–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –ø–æ–∑–∏—Ü–∏–π
                total_pos_value = sum(float(pos.get('position_value_usd', 0)) for pos in latest_positions.values())
                in_range_count = sum(1 for pos in latest_positions.values() if pos.get('in_range'))
                total_fees = sum(float(pos.get('fees_usd', 0) or 0) for pos in latest_positions.values())
                
                data["market_metrics"]["total_position_value"] = total_pos_value
                data["market_metrics"]["in_range_positions"] = in_range_count
                data["market_metrics"]["total_positions"] = len(latest_positions)
                data["market_metrics"]["total_accumulated_fees"] = total_fees
                data["market_metrics"]["in_range_ratio"] = (in_range_count / len(latest_positions) * 100) if latest_positions else 0
            
            print(f"‚úÖ –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ–±—Ä–∞–Ω—ã:")
            print(f"   üìà {len(data['dao_tokens_overview'])} —Ç–æ–∫–µ–Ω–æ–≤")
            print(f"   üß¨ {len(data['bio_lp_support'])} BIO LP –∑–∞–ø–∏—Å–µ–π") 
            print(f"   üèä {len(data['pool_performance'])} –ø—É–ª–æ–≤")
            print(f"   üìç {len(data['position_details'])} –ø–æ–∑–∏—Ü–∏–π")
            
            return data
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö: {e}")
            raise
    
    def _format_lp_intelligence_prompt(self, data: Dict[str, Any]) -> str:
        """–°–æ–∑–¥–∞–µ—Ç —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è LP Management –∞–Ω–∞–ª–∏–∑–∞"""
        
        prompt = f"""LP MANAGEMENT & MARKET MAKING INTELLIGENCE REPORT
Analysis Time: {datetime.utcnow().strftime('%Y-%m-%d %H:%M UTC')}
Data Source: Real-time Supabase snapshots

=== EXECUTIVE SUMMARY ===
Total Tokens Monitored: {len(data['dao_tokens_overview'])}
Active LP Positions: {data['market_metrics'].get('total_positions', 0)}
In-Range Ratio: {data['market_metrics'].get('in_range_ratio', 0):.1f}%
Current LP Value: ${data['market_metrics'].get('total_position_value', 0):,.2f}
Total Accumulated Fees: ${data['market_metrics'].get('total_accumulated_fees', 0):,.2f}

=== BIO TOKEN MARKET STATE ===
"""
        
        # BIO –º–µ—Ç—Ä–∏–∫–∏
        bio_price = data['market_metrics'].get('bio_price')
        bio_fdv = data['market_metrics'].get('bio_fdv')
        bio_24h = data['market_metrics'].get('bio_24h_change')
        bio_7d = data['market_metrics'].get('bio_7d_change')
        
        if bio_price:
            prompt += f"Current Price: ${bio_price}\n"
            prompt += f"FDV: ${bio_fdv:,.0f}\n" if bio_fdv else "FDV: N/A\n"
            prompt += f"24h Change: {bio_24h}%\n" if bio_24h else ""
            prompt += f"7d Change: {bio_7d}%\n" if bio_7d else ""
        
        # LP Coverage –∞–Ω–∞–ª–∏–∑
        target_lp = data['market_metrics'].get('total_target_lp', 0)
        current_lp = data['market_metrics'].get('total_current_lp', 0)
        lp_gap = data['market_metrics'].get('total_lp_gap', 0)
        coverage = data['market_metrics'].get('lp_coverage_ratio', 0)
        coverage_by_chain = data['market_metrics'].get('lp_coverage_by_chain', {})
        
        prompt += f"\n=== LP COVERAGE ANALYSIS ===\n"
        prompt += f"TARGET LIQUIDITY LOGIC: {data['market_metrics'].get('target_lp_logic', 'Not specified')}\n"
        prompt += f"‚Ä¢ Target LP Value: ${target_lp:,.2f} (1% –æ—Ç –æ–±—â–µ–≥–æ FDV —Ç–æ–∫–µ–Ω–æ–≤)\n"
        prompt += f"‚Ä¢ Current LP Value: ${current_lp:,.2f}\n"
        prompt += f"‚Ä¢ LP Gap: ${lp_gap:,.2f}\n"
        prompt += f"‚Ä¢ Overall Coverage: {coverage:.1f}%\n\n"
        
        # –î–µ—Ç–∞–ª—å–Ω–∞—è —Ä–∞–∑–±–∏–≤–∫–∞ –ø–æ —á–µ–π–Ω–∞–º
        prompt += "COVERAGE BY BLOCKCHAIN:\n"
        for chain, chain_data in coverage_by_chain.items():
            prompt += f"\n{chain.upper()}:\n"
            prompt += f"  Total FDV: ${chain_data['total_fdv']:,.0f}\n"
            prompt += f"  Target LP (1%): ${chain_data['total_target_lp']:,.0f}\n"
            prompt += f"  Current LP: ${chain_data['total_current_lp']:,.0f}\n"
            prompt += f"  Coverage: {chain_data['coverage_ratio']:.1f}%\n"
            
            # –¢–æ–ø-3 —Ç–æ–∫–µ–Ω–∞ –ø–æ coverage
            tokens_by_coverage = sorted(chain_data['tokens'], key=lambda x: x['coverage'], reverse=True)
            prompt += f"  Top tokens by coverage:\n"
            for i, token in enumerate(tokens_by_coverage[:3]):
                prompt += f"    {i+1}. {token['symbol']}: {token['coverage']:.1f}% (${token['current_lp']:,.0f}/${token['target_lp']:,.0f})\n"
        
        # –¢–æ–ø —Ç–æ–∫–µ–Ω—ã –ø–æ FDV –∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è–º
        prompt += f"\n=== TOKEN PERFORMANCE MATRIX ===\n"
        sorted_tokens = sorted(data['dao_tokens_overview'], 
                             key=lambda x: float(x.get('FDV', 0) or 0), reverse=True)
        
        for token in sorted_tokens[:10]:  # –¢–æ–ø 10
            symbol = token.get('Token', 'Unknown')
            fdv = float(token.get('FDV', 0) or 0)
            change_24h = token.get('24h Œî', 'N/A')
            tvl = float(token.get('TVL (all pools)', 0) or 0)
            fdv_tvl_ratio = float(token.get('FDV/TVL', 0) or 0)
            
            prompt += f"{symbol}: FDV ${fdv:,.0f}, 24h {change_24h}%, TVL ${tvl:,.0f}, FDV/TVL {fdv_tvl_ratio:.1f}x\n"
        
        # –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è BIO LP –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –ø–æ —Å–µ—Ç—è–º
        prompt += f"\n=== BIO LP SUPPORT BY NETWORK ===\n"
        networks = {}
        for item in data['bio_lp_support']:
            network = item.get('network_display', 'Unknown')
            if network not in networks:
                networks[network] = []
            networks[network].append(item)
        
        for network, items in networks.items():
            prompt += f"\n{network}:\n"
            for item in items:
                symbol = item.get('token_symbol', 'Unknown')
                target = float(item.get('target_lp_value_usd', 0) or 0)
                current = float(item.get('our_position_value_usd', 0) or 0)
                gap = float(item.get('lp_gap_usd', 0) or 0)
                tvl = float(item.get('tvl_usd', 0) or 0)
                
                coverage_pct = (current / target * 100) if target > 0 else 0
                prompt += f"  {symbol}: Target ${target:,.0f}, Current ${current:,.0f}, Gap ${gap:,.0f} ({coverage_pct:.1f}% coverage), Pool TVL ${tvl:,.0f}\n"
        
        # Pool Performance –¥–µ—Ç–∞–ª–∏
        prompt += f"\n=== POOL PERFORMANCE ANALYSIS ===\n"
        bio_pools = [p for p in data['pool_performance'] if 'BIO' in p.get('pool_name', '')]
        
        for pool in bio_pools:
            name = pool.get('pool_name', 'Unknown')
            network = pool.get('network', 'Unknown')
            tvl = float(pool.get('tvl_usd', 0) or 0)
            volume_24h = float(pool.get('volume_24h_usd', 0) or 0)
            price_change = pool.get('price_change_24h_percent', 'N/A')
            tvl_change = pool.get('tvl_change_percent', 'N/A')
            in_range_pos = pool.get('in_range_positions', 0)
            total_pos = pool.get('total_positions', 0)
            
            prompt += f"{name} ({network}):\n"
            prompt += f"  TVL: ${tvl:,.0f} (24h change: {tvl_change}%)\n"
            prompt += f"  Volume 24h: ${volume_24h:,.0f}\n"
            prompt += f"  Price change 24h: {price_change}%\n"
            prompt += f"  Positions: {in_range_pos}/{total_pos} in-range\n"
        
        # –ù–∞—à–∏ –ø–æ–∑–∏—Ü–∏–∏ –ø–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        prompt += f"\n=== OUR POSITION EFFICIENCY ANALYSIS ===\n"
        bio_positions = [p for p in data['position_details'] if 'BIO' in p.get('pool_name', '')]
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å—Ç–æ–∏–º–æ—Å—Ç–∏
        bio_positions.sort(key=lambda x: float(x.get('position_value_usd', 0)), reverse=True)
        
        for pos in bio_positions[:15]:  # –¢–æ–ø 15 –ø–æ–∑–∏—Ü–∏–π
            pool = pos.get('pool_name', 'Unknown')
            network = pos.get('network', 'Unknown')
            value = float(pos.get('position_value_usd', 0))
            fees = float(pos.get('fees_usd', 0) or 0)
            in_range = pos.get('in_range', False)
            age = pos.get('position_age_days', 0)
            health_score = pos.get('position_health_score', 'N/A')
            il_pct = pos.get('impermanent_loss_pct', 'N/A')
            
            status = "üü¢ IN-RANGE" if in_range else "üî¥ OUT-RANGE"
            prompt += f"{pool} ({network}): ${value:,.0f}, Fees ${fees:,.2f}, {status}, Age {age}d, Health {health_score}, IL {il_pct}%\n"
        
        return prompt
    
    def _create_grok_prompt(self, data: Dict[str, Any]) -> tuple:
        """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è Grok 4 —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ LP —Å—Ç—Ä–∞—Ç–µ–≥–∏—é"""
        
        system_prompt = """You are an elite DeFi strategist and market maker specializing in liquidity provision optimization for biotechnology tokens.

CORE MISSION: Analyze Bio Protocol ecosystem LP positions and provide actionable recommendations for:
1. Improving LP efficiency and reducing impermanent loss
2. Optimizing token price through strategic liquidity management  
3. Identifying market making opportunities across Solana, Ethereum, and Base

TARGET LIQUIDITY FRAMEWORK:
- Target LP = 1% of token FDV per blockchain
- This provides optimal depth for institutional trading
- Coverage below 50% indicates urgent LP gaps
- Coverage above 150% may signal over-allocation

KEY STRATEGIC PRINCIPLES:
- Prioritize high-volume, low-volatility pairs for stable returns
- Focus on tokens with strong fundamentals and growth potential
- Consider cross-chain arbitrage opportunities
- Balance between deep liquidity and capital efficiency

Provide specific, actionable recommendations with dollar amounts and reasoning."""

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è Grok
        formatted_data = self._format_lp_intelligence_prompt(data)
        
        user_prompt = f"""Analyze this Bio Protocol LP portfolio and provide strategic recommendations:

{formatted_data}

SPECIFIC ANALYSIS REQUESTED:

1. LP ALLOCATION STRATEGY:
   - Which tokens/pairs need immediate liquidity increases?
   - Which pairs are over-allocated and could be reduced?
   - Optimal LP distribution across chains (Solana vs Ethereum vs Base)

2. MARKET MAKING OPPORTUNITIES:
   - High-volume pairs with low LP coverage (arbitrage potential)
   - Cross-chain imbalances to exploit
   - Timing recommendations for LP adjustments

3. RISK MANAGEMENT:
   - Pairs with high impermanent loss exposure
   - Volatile tokens requiring active management
   - Diversification recommendations

4. SPECIFIC ACTION ITEMS:
   - Dollar amounts to move between pairs
   - Priority ranking of LP adjustments
   - Expected impact on token prices and trading volume

Be specific, quantitative, and actionable. Focus on maximizing returns while supporting token price appreciation."""

        return system_prompt, user_prompt
    
    async def get_grok_lp_analysis(self, data: Dict[str, Any]) -> Optional[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π LP –∞–Ω–∞–ª–∏–∑ –æ—Ç Grok 4"""
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        data_prompt = self._format_lp_intelligence_prompt(data)
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç—ã
        system_prompt, user_prompt = self._create_grok_prompt(data)
        
        headers = {
            "Authorization": f"Bearer {GROK_API_KEY}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": "grok-4-0709",
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "max_tokens": 3000,
            "temperature": 0.1
        }
        
        try:
            print("üöÄ –û—Ç–ø—Ä–∞–≤–ª—è—é –¥–∞–Ω–Ω—ã–µ –≤ Grok 4 –¥–ª—è LP –∞–Ω–∞–ª–∏–∑–∞...")
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    GROK_API_URL,
                    headers=headers,
                    json=payload,
                    timeout=150
                )
                
                if response.status_code == 200:
                    data = response.json()
                    if "choices" in data and len(data["choices"]) > 0:
                        analysis = data["choices"][0]["message"]["content"]
                        print(f"‚úÖ Grok 4 LP –∞–Ω–∞–ª–∏–∑ –ø–æ–ª—É—á–µ–Ω ({len(analysis)} —Å–∏–º–≤–æ–ª–æ–≤)")
                        return analysis
                    
                print(f"‚ùå Grok –æ—à–∏–±–∫–∞: {response.status_code} - {response.text}")
                return None
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ Grok –∑–∞–ø—Ä–æ—Å–∞: {e}")
            return None
    
    async def get_gpt_o3_analysis(self, data: Dict[str, Any]) -> Optional[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –æ—Ç GPT o3"""
        
        if not OPENAI_API_KEY:
            return None
            
        data_prompt = self._format_lp_intelligence_prompt(data)
        
        headers = {
            "Authorization": f"Bearer {OPENAI_API_KEY}",
            "Content-Type": "application/json"
        }
        
        system_prompt = """You are an elite quantitative DeFi analyst with advanced reasoning capabilities specializing in Bio Protocol ecosystem analysis.

ANALYTICAL FRAMEWORK:
- Target Liquidity Model: 1% of token FDV per blockchain provides optimal institutional trading depth
- Coverage Ratios: <50% urgent gaps, 50-100% healthy, >150% potential over-allocation
- LP Efficiency Metrics: Focus on fees/capital ratio, impermanent loss minimization, volume/liquidity ratio

Use step-by-step reasoning to provide quantitative insights on:
1. LP capital allocation efficiency across chains (Solana, Ethereum, Base)
2. Mathematical optimization of position ranges and sizes
3. Risk-adjusted return calculations for each LP pair
4. Cross-chain arbitrage opportunities and optimal execution

Provide mathematical models, specific dollar recommendations, and quantified risk assessments."""
        
        payload = {
            "model": "o3",
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"Analyze this LP portfolio data and provide quantitative insights:\n\n{data_prompt}"}
            ],
            "max_completion_tokens": 2000
        }
        
        try:
            print("ü§ñ –û—Ç–ø—Ä–∞–≤–ª—è—é –¥–∞–Ω–Ω—ã–µ –≤ GPT o3 –¥–ª—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞...")
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    OPENAI_API_URL,
                    headers=headers,
                    json=payload,
                    timeout=120
                )
                
                if response.status_code == 200:
                    data = response.json()
                    if "choices" in data and len(data["choices"]) > 0:
                        analysis = data["choices"][0]["message"]["content"]
                        print(f"‚úÖ GPT o3 –∞–Ω–∞–ª–∏–∑ –ø–æ–ª—É—á–µ–Ω ({len(analysis)} —Å–∏–º–≤–æ–ª–æ–≤)")
                        return analysis
                    
                print(f"‚ùå GPT o3 –æ—à–∏–±–∫–∞: {response.status_code} - {response.text}")
                return None
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ GPT o3 –∑–∞–ø—Ä–æ—Å–∞: {e}")
            return None
    
    async def send_telegram_report(self, grok_analysis: str, gpt_analysis: str, raw_data: Dict) -> bool:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∞–Ω–∞–ª–∏–∑ –≤ Telegram"""
        
        try:
            telegram = TelegramSender()
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –æ—Ç—á–µ—Ç–∞
            header = f"""üß¨ <b>BIO PROTOCOL LP INTELLIGENCE</b>
üìÖ {self.analysis_time.strftime('%d.%m.%Y %H:%M UTC')}
üí∞ Portfolio: <b>${raw_data['market_metrics'].get('total_position_value', 0):,.0f}</b>
üìç Positions: <b>{raw_data['market_metrics'].get('total_positions', 0)}</b> (In-range: <b>{raw_data['market_metrics'].get('in_range_ratio', 0):.1f}%</b>)
üéØ LP Coverage: <b>{raw_data['market_metrics'].get('lp_coverage_ratio', 0):.1f}%</b>
üí∏ LP Gap: <b>${raw_data['market_metrics'].get('total_lp_gap', 0):,.0f}</b>

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"""
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
            await telegram.send_message(header)
            await asyncio.sleep(1)
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∞–Ω–∞–ª–∏–∑ Grok
            if grok_analysis:
                grok_header = "üöÄ <b>GROK 4 LP STRATEGY ANALYSIS</b>"
                await telegram.send_message(grok_header)
                await asyncio.sleep(1)
                
                # –†–∞–∑–±–∏–≤–∞–µ–º –¥–ª–∏–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–∞ —á–∞—Å—Ç–∏ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ë–ï–ó HTML —Ä–∞–∑–º–µ—Ç–∫–∏
                grok_parts = self._split_analysis_text(grok_analysis, 3000)
                for i, part in enumerate(grok_parts):
                    await telegram.send_message(part, parse_mode=None)  # –ë–µ–∑ HTML
                    if i < len(grok_parts) - 1:
                        await asyncio.sleep(2)
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∞–Ω–∞–ª–∏–∑ GPT
            if gpt_analysis:
                await asyncio.sleep(2)
                gpt_header = "ü§ñ <b>GPT O3 QUANTITATIVE ANALYSIS</b>"
                await telegram.send_message(gpt_header)
                await asyncio.sleep(1)
                
                # –†–∞–∑–±–∏–≤–∞–µ–º –¥–ª–∏–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–∞ —á–∞—Å—Ç–∏ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ë–ï–ó HTML —Ä–∞–∑–º–µ—Ç–∫–∏
                gpt_parts = self._split_analysis_text(gpt_analysis, 3000)
                for i, part in enumerate(gpt_parts):
                    await telegram.send_message(part, parse_mode=None)  # –ë–µ–∑ HTML
                    if i < len(gpt_parts) - 1:
                        await asyncio.sleep(2)
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            await asyncio.sleep(2)
            metrics_text = f"""üìä <b>KEY METRICS SUMMARY</b>
‚Ä¢ BIO Price: <b>${raw_data['market_metrics'].get('bio_price', 0):.6f}</b> ({raw_data['market_metrics'].get('bio_24h_change', 0):+.2f}% 24h)
‚Ä¢ BIO FDV: <b>${raw_data['market_metrics'].get('bio_fdv', 0):,.0f}</b>
‚Ä¢ Total Target LP: <b>${raw_data['market_metrics'].get('total_target_lp', 0):,.0f}</b>
‚Ä¢ Current LP: <b>${raw_data['market_metrics'].get('total_current_lp', 0):,.0f}</b>
‚Ä¢ Fees Accumulated: <b>${raw_data['market_metrics'].get('total_accumulated_fees', 0):,.2f}</b>"""
            
            await telegram.send_message(metrics_text)
            
            print("‚úÖ LP Intelligence –æ—Ç—á–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –≤ Telegram")
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Telegram: {e}")
            return False
    
    def _escape_html_chars(self, text: str) -> str:
        """–≠–∫—Ä–∞–Ω–∏—Ä—É–µ—Ç HTML —Å–∏–º–≤–æ–ª—ã –¥–ª—è Telegram"""
        if not text:
            return text
        # –ó–∞–º–µ–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã, —Å–æ—Ö—Ä–∞–Ω—è—è –±–∞–∑–æ–≤—É—é —Ä–∞–∑–º–µ—Ç–∫—É
        text = text.replace('&', '&amp;')
        text = text.replace('<', '&lt;')
        text = text.replace('>', '&gt;')
        # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ –≤ —Ç–µ–≥–∞—Ö
        import re
        text = re.sub(r'(?<!<[^>]*)\%(?![^<]*>)', ' percent', text)
        return text
    
    def _split_analysis_text(self, text: str, max_length: int) -> List[str]:
        """–†–∞–∑–±–∏–≤–∞–µ—Ç –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞ —á–∞—Å—Ç–∏ –¥–ª—è Telegram"""
        if len(text) <= max_length:
            return [text]
        
        parts = []
        current_part = ""
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ –∞–±–∑–∞—Ü–∞–º
        paragraphs = text.split('\n\n')
        
        for paragraph in paragraphs:
            # –ï—Å–ª–∏ –∞–±–∑–∞—Ü —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π, —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º
            if len(paragraph) > max_length:
                sentences = paragraph.split('. ')
                for sentence in sentences:
                    if len(current_part + sentence) > max_length:
                        if current_part:
                            parts.append(current_part.strip())
                            current_part = sentence + '. '
                        else:
                            # –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ, —Ä–∞–∑–±–∏–≤–∞–µ–º –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ
                            parts.append(sentence[:max_length-3] + "...")
                    else:
                        current_part += sentence + '. '
            else:
                if len(current_part + paragraph) > max_length:
                    if current_part:
                        parts.append(current_part.strip())
                        current_part = paragraph + '\n\n'
                    else:
                        parts.append(paragraph)
                else:
                    current_part += paragraph + '\n\n'
        
        if current_part.strip():
            parts.append(current_part.strip())
        
        return parts

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è LP –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞"""
    
    print("üß¨ BIO PROTOCOL LP INTELLIGENCE ANALYZER")
    print("=" * 60)
    print(f"‚è∞ –ó–∞–ø—É—Å–∫: {datetime.utcnow().strftime('%Y-%m-%d %H:%M UTC')}")
    print("üéØ –§–æ–∫—É—Å: LP Management & Market Making Optimization")
    
    analyzer = BioLPAnalyzer()
    
    try:
        # 1. –°–æ–±–∏—Ä–∞–µ–º –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        portfolio_data = await analyzer.collect_comprehensive_data()
        
        if not any([portfolio_data['dao_tokens_overview'], portfolio_data['bio_lp_support'], 
                   portfolio_data['position_details']]):
            print("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            return
        
        print(f"\nüöÄ –ó–∞–ø—É—Å–∫–∞—é AI –∞–Ω–∞–ª–∏–∑ –ø–æ—Ä—Ç—Ñ–µ–ª—è...")
        
        # 2. –ü–æ–ª—É—á–∞–µ–º –∞–Ω–∞–ª–∏–∑—ã –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        grok_task = analyzer.get_grok_lp_analysis(portfolio_data)
        gpt_task = analyzer.get_gpt_o3_analysis(portfolio_data) if OPENAI_API_KEY else None
        
        # –ñ–¥–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        results = await asyncio.gather(
            grok_task,
            gpt_task if gpt_task else asyncio.sleep(0),
            return_exceptions=True
        )
        
        grok_analysis = results[0] if not isinstance(results[0], Exception) else None
        gpt_analysis = results[1] if gpt_task and not isinstance(results[1], Exception) else None
        
        # 3. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        if grok_analysis or gpt_analysis:
            await analyzer.send_telegram_report(grok_analysis, gpt_analysis, portfolio_data)
            
        else:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –æ—Ç AI –º–æ–¥–µ–ª–µ–π")
    
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main()) 